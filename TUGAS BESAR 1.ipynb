{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kxqGCCSoSepP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = ('/content/drive/MyDrive/dataset_new/train')\n",
        "validation_dir = ('/content/drive/MyDrive/dataset_new/val')"
      ],
      "metadata": {
        "id": "yxn8OgGU0MZW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_belimbing_dir = os.path.join(train_dir, 'Belimbing Wuluh')\n",
        "train_jambu_dir = os.path.join(train_dir, 'Jambu biji')\n",
        "train_jeruk_dir = os.path.join(train_dir, 'Jeruk')\n",
        "train_kemangi_dir = os.path.join(train_dir, 'Kemangi')\n",
        "train_lidah_dir = os.path.join(train_dir, 'Lidah buaya')\n",
        "train_nangka_dir = os.path.join(train_dir, 'Nangka')\n",
        "train_pandan_dir = os.path.join(train_dir, 'Pandan')\n",
        "train_pepaya_dir = os.path.join(train_dir, 'Pepaya')\n",
        "train_seledri_dir = os.path.join(train_dir, 'Seledri')\n",
        "train_sirih_dir = os.path.join(train_dir, 'Sirih')\n",
        "\n",
        "val_belimbing_dir = os.path.join(validation_dir, 'Belimbing Wuluh')\n",
        "val_jambu_dir = os.path.join(validation_dir, 'Jambu biji')\n",
        "val_jeruk_dir = os.path.join(validation_dir, 'Jeruk')\n",
        "val_kemangi_dir = os.path.join(validation_dir, 'Kemangi')\n",
        "val_lidah_dir = os.path.join(validation_dir, 'Lidah buaya')\n",
        "val_nangka_dir = os.path.join(validation_dir, 'Nangka')\n",
        "val_pandan_dir = os.path.join(validation_dir, 'Pandan')\n",
        "val_pepaya_dir = os.path.join(validation_dir, 'Pepaya')\n",
        "val_seledri_dir = os.path.join(validation_dir, 'Seledri')\n",
        "val_sirih_dir = os.path.join(validation_dir, 'Sirih')"
      ],
      "metadata": {
        "id": "Y29AE33A0igB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        " \n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')"
      ],
      "metadata": {
        "id": "9_wRjL981IH5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URbB0Jp31PSu",
        "outputId": "d9cdf7f0-bcc7-4618-aaac-46da73f47d04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2590 images belonging to 10 classes.\n",
            "Found 870 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "sFFAyjJo1WF4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYBHYEXA1Y1Q",
        "outputId": "f34a6384-de6a-499b-eec9-42848efdef6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,457,738\n",
            "Trainable params: 3,457,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ICYwFdpq1bvU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100, \n",
        "      epochs=150,\n",
        "      validation_data=validation_generator, \n",
        "      validation_steps=150,  \n",
        "      verbose=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ7T44k61ezG",
        "outputId": "d37d5cb0-9734-4441-b768-b69d8e9ae7ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9339 - accuracy: 0.2780WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 150 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 281s 3s/step - loss: 1.9339 - accuracy: 0.2780 - val_loss: 1.4074 - val_accuracy: 0.4931\n",
            "Epoch 2/150\n",
            "100/100 [==============================] - 156s 2s/step - loss: 1.3171 - accuracy: 0.5100\n",
            "Epoch 3/150\n",
            "100/100 [==============================] - 135s 1s/step - loss: 1.0772 - accuracy: 0.6160\n",
            "Epoch 4/150\n",
            "100/100 [==============================] - 108s 1s/step - loss: 1.0285 - accuracy: 0.6380\n",
            "Epoch 5/150\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.8649 - accuracy: 0.6870\n",
            "Epoch 6/150\n",
            "100/100 [==============================] - 90s 900ms/step - loss: 0.7838 - accuracy: 0.7300\n",
            "Epoch 7/150\n",
            "100/100 [==============================] - 92s 911ms/step - loss: 0.7492 - accuracy: 0.7170\n",
            "Epoch 8/150\n",
            "100/100 [==============================] - 98s 974ms/step - loss: 0.6445 - accuracy: 0.7650\n",
            "Epoch 9/150\n",
            "100/100 [==============================] - 90s 899ms/step - loss: 0.6355 - accuracy: 0.7780\n",
            "Epoch 10/150\n",
            "100/100 [==============================] - 88s 873ms/step - loss: 0.5369 - accuracy: 0.7960\n",
            "Epoch 11/150\n",
            "100/100 [==============================] - 86s 856ms/step - loss: 0.4868 - accuracy: 0.8250\n",
            "Epoch 12/150\n",
            "100/100 [==============================] - 89s 890ms/step - loss: 0.5014 - accuracy: 0.8250\n",
            "Epoch 13/150\n",
            "100/100 [==============================] - 87s 873ms/step - loss: 0.5039 - accuracy: 0.8120\n",
            "Epoch 14/150\n",
            "100/100 [==============================] - 91s 902ms/step - loss: 0.4465 - accuracy: 0.8420\n",
            "Epoch 15/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.3916 - accuracy: 0.8560\n",
            "Epoch 16/150\n",
            "100/100 [==============================] - 91s 910ms/step - loss: 0.3829 - accuracy: 0.8550\n",
            "Epoch 17/150\n",
            "100/100 [==============================] - 87s 868ms/step - loss: 0.3920 - accuracy: 0.8620\n",
            "Epoch 18/150\n",
            "100/100 [==============================] - 91s 913ms/step - loss: 0.3628 - accuracy: 0.8650\n",
            "Epoch 19/150\n",
            "100/100 [==============================] - 88s 871ms/step - loss: 0.3294 - accuracy: 0.8890\n",
            "Epoch 20/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.3068 - accuracy: 0.8910\n",
            "Epoch 21/150\n",
            "100/100 [==============================] - 91s 908ms/step - loss: 0.2700 - accuracy: 0.8960\n",
            "Epoch 22/150\n",
            "100/100 [==============================] - 89s 893ms/step - loss: 0.3217 - accuracy: 0.8930\n",
            "Epoch 23/150\n",
            "100/100 [==============================] - 90s 904ms/step - loss: 0.2369 - accuracy: 0.9200\n",
            "Epoch 24/150\n",
            "100/100 [==============================] - 88s 874ms/step - loss: 0.3153 - accuracy: 0.8960\n",
            "Epoch 25/150\n",
            "100/100 [==============================] - 91s 902ms/step - loss: 0.2780 - accuracy: 0.8990\n",
            "Epoch 26/150\n",
            "100/100 [==============================] - 87s 863ms/step - loss: 0.2593 - accuracy: 0.9110\n",
            "Epoch 27/150\n",
            "100/100 [==============================] - 90s 895ms/step - loss: 0.1708 - accuracy: 0.9420\n",
            "Epoch 28/150\n",
            "100/100 [==============================] - 88s 876ms/step - loss: 0.2387 - accuracy: 0.9130\n",
            "Epoch 29/150\n",
            "100/100 [==============================] - 89s 886ms/step - loss: 0.2164 - accuracy: 0.9180\n",
            "Epoch 30/150\n",
            "100/100 [==============================] - 90s 901ms/step - loss: 0.2315 - accuracy: 0.9140\n",
            "Epoch 31/150\n",
            "100/100 [==============================] - 88s 876ms/step - loss: 0.1875 - accuracy: 0.9320\n",
            "Epoch 32/150\n",
            "100/100 [==============================] - 88s 877ms/step - loss: 0.2555 - accuracy: 0.9240\n",
            "Epoch 33/150\n",
            "100/100 [==============================] - 92s 918ms/step - loss: 0.1988 - accuracy: 0.9260\n",
            "Epoch 34/150\n",
            "100/100 [==============================] - 89s 890ms/step - loss: 0.1890 - accuracy: 0.9380\n",
            "Epoch 35/150\n",
            "100/100 [==============================] - 90s 896ms/step - loss: 0.1766 - accuracy: 0.9430\n",
            "Epoch 36/150\n",
            "100/100 [==============================] - 90s 894ms/step - loss: 0.1602 - accuracy: 0.9530\n",
            "Epoch 37/150\n",
            "100/100 [==============================] - 92s 916ms/step - loss: 0.1818 - accuracy: 0.9440\n",
            "Epoch 38/150\n",
            "100/100 [==============================] - 88s 877ms/step - loss: 0.1988 - accuracy: 0.9330\n",
            "Epoch 39/150\n",
            "100/100 [==============================] - 88s 875ms/step - loss: 0.1764 - accuracy: 0.9400\n",
            "Epoch 40/150\n",
            "100/100 [==============================] - 90s 903ms/step - loss: 0.2294 - accuracy: 0.9150\n",
            "Epoch 41/150\n",
            "100/100 [==============================] - 88s 878ms/step - loss: 0.1597 - accuracy: 0.9530\n",
            "Epoch 42/150\n",
            "100/100 [==============================] - 88s 881ms/step - loss: 0.1357 - accuracy: 0.9530\n",
            "Epoch 43/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.1388 - accuracy: 0.9540\n",
            "Epoch 44/150\n",
            "100/100 [==============================] - 90s 897ms/step - loss: 0.1426 - accuracy: 0.9520\n",
            "Epoch 45/150\n",
            "100/100 [==============================] - 87s 868ms/step - loss: 0.1529 - accuracy: 0.9510\n",
            "Epoch 46/150\n",
            "100/100 [==============================] - 90s 897ms/step - loss: 0.1573 - accuracy: 0.9510\n",
            "Epoch 47/150\n",
            "100/100 [==============================] - 89s 887ms/step - loss: 0.1224 - accuracy: 0.9570\n",
            "Epoch 48/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.0926 - accuracy: 0.9700\n",
            "Epoch 49/150\n",
            "100/100 [==============================] - 88s 880ms/step - loss: 0.1180 - accuracy: 0.9550\n",
            "Epoch 50/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.0977 - accuracy: 0.9710\n",
            "Epoch 51/150\n",
            "100/100 [==============================] - 87s 871ms/step - loss: 0.1263 - accuracy: 0.9510\n",
            "Epoch 52/150\n",
            "100/100 [==============================] - 90s 895ms/step - loss: 0.1395 - accuracy: 0.9570\n",
            "Epoch 53/150\n",
            "100/100 [==============================] - 88s 881ms/step - loss: 0.1152 - accuracy: 0.9600\n",
            "Epoch 54/150\n",
            "100/100 [==============================] - 88s 875ms/step - loss: 0.0764 - accuracy: 0.9770\n",
            "Epoch 55/150\n",
            "100/100 [==============================] - 91s 903ms/step - loss: 0.1550 - accuracy: 0.9530\n",
            "Epoch 56/150\n",
            "100/100 [==============================] - 88s 875ms/step - loss: 0.1301 - accuracy: 0.9590\n",
            "Epoch 57/150\n",
            "100/100 [==============================] - 87s 872ms/step - loss: 0.1407 - accuracy: 0.9490\n",
            "Epoch 58/150\n",
            "100/100 [==============================] - 89s 886ms/step - loss: 0.1147 - accuracy: 0.9590\n",
            "Epoch 59/150\n",
            "100/100 [==============================] - 87s 869ms/step - loss: 0.1006 - accuracy: 0.9710\n",
            "Epoch 60/150\n",
            "100/100 [==============================] - 87s 870ms/step - loss: 0.0549 - accuracy: 0.9870\n",
            "Epoch 61/150\n",
            "100/100 [==============================] - 89s 889ms/step - loss: 0.1156 - accuracy: 0.9650\n",
            "Epoch 62/150\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 0.1243 - accuracy: 0.9620\n",
            "Epoch 63/150\n",
            "100/100 [==============================] - 88s 877ms/step - loss: 0.0919 - accuracy: 0.9710\n",
            "Epoch 64/150\n",
            "100/100 [==============================] - 93s 925ms/step - loss: 0.0713 - accuracy: 0.9770\n",
            "Epoch 65/150\n",
            "100/100 [==============================] - 88s 879ms/step - loss: 0.0940 - accuracy: 0.9650\n",
            "Epoch 66/150\n",
            "100/100 [==============================] - 87s 870ms/step - loss: 0.0877 - accuracy: 0.9730\n",
            "Epoch 67/150\n",
            "100/100 [==============================] - 90s 904ms/step - loss: 0.0915 - accuracy: 0.9650\n",
            "Epoch 68/150\n",
            "100/100 [==============================] - 88s 881ms/step - loss: 0.0948 - accuracy: 0.9610\n",
            "Epoch 69/150\n",
            "100/100 [==============================] - 91s 911ms/step - loss: 0.0470 - accuracy: 0.9850\n",
            "Epoch 70/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.1018 - accuracy: 0.9700\n",
            "Epoch 71/150\n",
            "100/100 [==============================] - 90s 893ms/step - loss: 0.1290 - accuracy: 0.9520\n",
            "Epoch 72/150\n",
            "100/100 [==============================] - 92s 919ms/step - loss: 0.1018 - accuracy: 0.9700\n",
            "Epoch 73/150\n",
            "100/100 [==============================] - 90s 896ms/step - loss: 0.0772 - accuracy: 0.9740\n",
            "Epoch 74/150\n",
            "100/100 [==============================] - 90s 896ms/step - loss: 0.0736 - accuracy: 0.9760\n",
            "Epoch 75/150\n",
            "100/100 [==============================] - 90s 897ms/step - loss: 0.0702 - accuracy: 0.9720\n",
            "Epoch 76/150\n",
            "100/100 [==============================] - 91s 906ms/step - loss: 0.0764 - accuracy: 0.9730\n",
            "Epoch 77/150\n",
            "100/100 [==============================] - 90s 900ms/step - loss: 0.0616 - accuracy: 0.9800\n",
            "Epoch 78/150\n",
            "100/100 [==============================] - 89s 886ms/step - loss: 0.0840 - accuracy: 0.9710\n",
            "Epoch 79/150\n",
            "100/100 [==============================] - 88s 874ms/step - loss: 0.1317 - accuracy: 0.9600\n",
            "Epoch 80/150\n",
            "100/100 [==============================] - 90s 898ms/step - loss: 0.0976 - accuracy: 0.9680\n",
            "Epoch 81/150\n",
            "100/100 [==============================] - 89s 880ms/step - loss: 0.1166 - accuracy: 0.9650\n",
            "Epoch 82/150\n",
            "100/100 [==============================] - 89s 892ms/step - loss: 0.0572 - accuracy: 0.9800\n",
            "Epoch 83/150\n",
            "100/100 [==============================] - 88s 872ms/step - loss: 0.0690 - accuracy: 0.9740\n",
            "Epoch 84/150\n",
            "100/100 [==============================] - 92s 915ms/step - loss: 0.0950 - accuracy: 0.9690\n",
            "Epoch 85/150\n",
            "100/100 [==============================] - 88s 873ms/step - loss: 0.0457 - accuracy: 0.9850\n",
            "Epoch 86/150\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 0.1015 - accuracy: 0.9720\n",
            "Epoch 87/150\n",
            "100/100 [==============================] - 88s 879ms/step - loss: 0.0814 - accuracy: 0.9790\n",
            "Epoch 88/150\n",
            "100/100 [==============================] - 89s 882ms/step - loss: 0.0715 - accuracy: 0.9730\n",
            "Epoch 89/150\n",
            "100/100 [==============================] - 90s 898ms/step - loss: 0.0570 - accuracy: 0.9810\n",
            "Epoch 90/150\n",
            "100/100 [==============================] - 90s 890ms/step - loss: 0.0659 - accuracy: 0.9830\n",
            "Epoch 91/150\n",
            "100/100 [==============================] - 89s 882ms/step - loss: 0.0608 - accuracy: 0.9790\n",
            "Epoch 92/150\n",
            "100/100 [==============================] - 91s 907ms/step - loss: 0.0609 - accuracy: 0.9760\n",
            "Epoch 93/150\n",
            "100/100 [==============================] - 89s 882ms/step - loss: 0.0432 - accuracy: 0.9870\n",
            "Epoch 94/150\n",
            "100/100 [==============================] - 86s 853ms/step - loss: 0.0819 - accuracy: 0.9730\n",
            "Epoch 95/150\n",
            "100/100 [==============================] - 90s 893ms/step - loss: 0.0771 - accuracy: 0.9690\n",
            "Epoch 96/150\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 0.0671 - accuracy: 0.9790\n",
            "Epoch 97/150\n",
            "100/100 [==============================] - 88s 877ms/step - loss: 0.1422 - accuracy: 0.9530\n",
            "Epoch 98/150\n",
            "100/100 [==============================] - 91s 905ms/step - loss: 0.0574 - accuracy: 0.9840\n",
            "Epoch 99/150\n",
            "100/100 [==============================] - 91s 907ms/step - loss: 0.0278 - accuracy: 0.9910\n",
            "Epoch 100/150\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 0.0478 - accuracy: 0.9860\n",
            "Epoch 101/150\n",
            "100/100 [==============================] - 92s 913ms/step - loss: 0.1247 - accuracy: 0.9630\n",
            "Epoch 102/150\n",
            "100/100 [==============================] - 90s 895ms/step - loss: 0.0800 - accuracy: 0.9780\n",
            "Epoch 103/150\n",
            "100/100 [==============================] - 88s 879ms/step - loss: 0.0639 - accuracy: 0.9790\n",
            "Epoch 104/150\n",
            "100/100 [==============================] - 89s 891ms/step - loss: 0.0663 - accuracy: 0.9820\n",
            "Epoch 105/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.0394 - accuracy: 0.9870\n",
            "Epoch 106/150\n",
            "100/100 [==============================] - 88s 875ms/step - loss: 0.0584 - accuracy: 0.9820\n",
            "Epoch 107/150\n",
            "100/100 [==============================] - 89s 889ms/step - loss: 0.0349 - accuracy: 0.9860\n",
            "Epoch 108/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.0813 - accuracy: 0.9730\n",
            "Epoch 109/150\n",
            "100/100 [==============================] - 86s 859ms/step - loss: 0.0503 - accuracy: 0.9820\n",
            "Epoch 110/150\n",
            "100/100 [==============================] - 87s 869ms/step - loss: 0.0482 - accuracy: 0.9830\n",
            "Epoch 111/150\n",
            "100/100 [==============================] - 88s 880ms/step - loss: 0.0614 - accuracy: 0.9820\n",
            "Epoch 112/150\n",
            "100/100 [==============================] - 89s 888ms/step - loss: 0.0537 - accuracy: 0.9840\n",
            "Epoch 113/150\n",
            "100/100 [==============================] - 90s 893ms/step - loss: 0.0621 - accuracy: 0.9810\n",
            "Epoch 114/150\n",
            "100/100 [==============================] - 90s 893ms/step - loss: 0.0461 - accuracy: 0.9850\n",
            "Epoch 115/150\n",
            "100/100 [==============================] - 89s 885ms/step - loss: 0.0412 - accuracy: 0.9870\n",
            "Epoch 116/150\n",
            "100/100 [==============================] - 88s 884ms/step - loss: 0.0242 - accuracy: 0.9910\n",
            "Epoch 117/150\n",
            "100/100 [==============================] - 88s 879ms/step - loss: 0.2145 - accuracy: 0.9390\n",
            "Epoch 118/150\n",
            "100/100 [==============================] - 89s 887ms/step - loss: 0.1927 - accuracy: 0.9520\n",
            "Epoch 119/150\n",
            "100/100 [==============================] - 88s 877ms/step - loss: 0.1175 - accuracy: 0.9640\n",
            "Epoch 120/150\n",
            "100/100 [==============================] - 88s 873ms/step - loss: 0.0645 - accuracy: 0.9830\n",
            "Epoch 121/150\n",
            "100/100 [==============================] - 87s 868ms/step - loss: 0.0481 - accuracy: 0.9850\n",
            "Epoch 122/150\n",
            "100/100 [==============================] - 89s 891ms/step - loss: 0.0669 - accuracy: 0.9770\n",
            "Epoch 123/150\n",
            "100/100 [==============================] - 88s 883ms/step - loss: 0.0466 - accuracy: 0.9820\n",
            "Epoch 124/150\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 0.0778 - accuracy: 0.9830\n",
            "Epoch 125/150\n",
            "100/100 [==============================] - 88s 877ms/step - loss: 0.1013 - accuracy: 0.9720\n",
            "Epoch 126/150\n",
            "100/100 [==============================] - 91s 903ms/step - loss: 0.0868 - accuracy: 0.9720\n",
            "Epoch 127/150\n",
            "100/100 [==============================] - 90s 894ms/step - loss: 0.0342 - accuracy: 0.9910\n",
            "Epoch 128/150\n",
            "100/100 [==============================] - 88s 875ms/step - loss: 0.0249 - accuracy: 0.9880\n",
            "Epoch 129/150\n",
            "100/100 [==============================] - 88s 883ms/step - loss: 0.0203 - accuracy: 0.9920\n",
            "Epoch 130/150\n",
            "100/100 [==============================] - 87s 866ms/step - loss: 0.0261 - accuracy: 0.9910\n",
            "Epoch 131/150\n",
            "100/100 [==============================] - 88s 880ms/step - loss: 0.0454 - accuracy: 0.9850\n",
            "Epoch 132/150\n",
            "100/100 [==============================] - 88s 873ms/step - loss: 0.0344 - accuracy: 0.9890\n",
            "Epoch 133/150\n",
            "100/100 [==============================] - 89s 888ms/step - loss: 0.1053 - accuracy: 0.9690\n",
            "Epoch 134/150\n",
            "100/100 [==============================] - 86s 861ms/step - loss: 0.1604 - accuracy: 0.9770\n",
            "Epoch 135/150\n",
            "100/100 [==============================] - 90s 893ms/step - loss: 0.1192 - accuracy: 0.9720\n",
            "Epoch 136/150\n",
            "100/100 [==============================] - 87s 868ms/step - loss: 0.0607 - accuracy: 0.9860\n",
            "Epoch 137/150\n",
            "100/100 [==============================] - 90s 893ms/step - loss: 0.0383 - accuracy: 0.9900\n",
            "Epoch 138/150\n",
            "100/100 [==============================] - 89s 883ms/step - loss: 0.0217 - accuracy: 0.9940\n",
            "Epoch 139/150\n",
            "100/100 [==============================] - 86s 860ms/step - loss: 0.0428 - accuracy: 0.9890\n",
            "Epoch 140/150\n",
            "100/100 [==============================] - 89s 883ms/step - loss: 0.0297 - accuracy: 0.9900\n",
            "Epoch 141/150\n",
            "100/100 [==============================] - 88s 881ms/step - loss: 0.0129 - accuracy: 0.9950\n",
            "Epoch 142/150\n",
            "100/100 [==============================] - 85s 850ms/step - loss: 0.0345 - accuracy: 0.9900\n",
            "Epoch 143/150\n",
            "100/100 [==============================] - 86s 864ms/step - loss: 0.0807 - accuracy: 0.9820\n",
            "Epoch 144/150\n",
            "100/100 [==============================] - 88s 879ms/step - loss: 0.0303 - accuracy: 0.9880\n",
            "Epoch 145/150\n",
            "100/100 [==============================] - 87s 872ms/step - loss: 0.0340 - accuracy: 0.9900\n",
            "Epoch 146/150\n",
            "100/100 [==============================] - 88s 868ms/step - loss: 0.0430 - accuracy: 0.9840\n",
            "Epoch 147/150\n",
            "100/100 [==============================] - 89s 886ms/step - loss: 0.1817 - accuracy: 0.9600\n",
            "Epoch 148/150\n",
            "100/100 [==============================] - 89s 891ms/step - loss: 0.0788 - accuracy: 0.9770\n",
            "Epoch 149/150\n",
            "100/100 [==============================] - 88s 873ms/step - loss: 0.0392 - accuracy: 0.9840\n",
            "Epoch 150/150\n",
            "100/100 [==============================] - 88s 880ms/step - loss: 0.0415 - accuracy: 0.9800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5cb9932e90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_BASE_PATH = \"Model\"\n",
        "PROJECT_NAME = \"TUBES\"\n",
        "SAVE_MODEL_NAME = \"modeltubes.h5\"\n",
        "save_model_path = os.path.join(MODEL_BASE_PATH, PROJECT_NAME, SAVE_MODEL_NAME)\n",
        "if os.path.exists(os.path.join(MODEL_BASE_PATH, PROJECT_NAME)) == False:\n",
        "    os.makedirs(os.path.join(MODEL_BASE_PATH, PROJECT_NAME))\n",
        "    \n",
        "print('Saving Model At {}...'.format(save_model_path))\n",
        "model.save(save_model_path,include_optimizer=False)"
      ],
      "metadata": {
        "id": "tbfdfPXt6_C8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}